# torch.nn å®ç° çº¿æ€§å›å½’å®ç°
import torch.utils.data as Data
import torch
import numpy as np
import torch.nn as nn
from torch.nn import init   # è°ƒç”¨ğ¢ğ§ğ¢ğ­. ğ§ğ¨ğ«ğ¦ğšğ¥æ¨¡å—é€šè¿‡æ­£æ€åˆ†å¸ƒå¯¹çº¿æ€§ å›å½’ä¸­çš„æƒé‡å’Œåå·®è¿›è¡Œåˆå§‹åŒ–
import torch.optim as optim # ä¼˜åŒ–å™¨


num_inputs = 2              # ç‰¹å¾æ•°
num_examples = 1000         # æ ·æœ¬æ•°
true_w = [2, -3.4]          # çœŸå®çš„æƒé‡w
true_b = 4.2                # çœŸå®çš„åå·®c
# éœ€è¦å¾—å‡ºçœŸå®çš„æ ‡ç­¾ label
# np.random.normal(0, 1, (num_examples, num_inputs)) ï¼š ç”Ÿæˆäº† 1000è¡Œ * 2åˆ—çš„ 0-1ä¹‹é—´çš„ çŸ©é˜µæ•°æ®ï¼ˆétensor ä¸ºnpæ•°å­¦æ•°ç»„ï¼‰ã€‚æµ‹è¯•ï¼šx = np.random.normal(0, 1, (5, 2))ã€‚np.random.normal() è¿”å›ä¸€ç»„ç¬¦åˆé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦éšæœºæ•°ã€‚
features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)  # ç‰¹å¾ featureçš„æ•°æ®ï¼Œä¼šç”Ÿæˆä¸€ä¸ª 1000 è¡Œ * 2åˆ—çš„çŸ©é˜µæ•°æ®ä»£è¡¨ç‰¹å¾feature
labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b                       # æ ‡ç­¾ labelè®¡ç®—ï¼Œ1*2 çš„çŸ©é˜µå’Œ 2*1çš„çŸ©é˜µç›¸ä¹˜ + åŠ ä¸Šåå·®ã€‚features[:, 0] å–çš„æ˜¯ç¬¬ä¸€åˆ—ï¼Œfeatures[:, 1] å–ç¬¬äºŒåˆ—
labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)        # åŠ ä¸Š å™ªå£°


lr = 0.03
batch_size = 10
# å°†è®­ç»ƒæ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾ç»„åˆ
dataset = Data.TensorDataset(features, labels)

# æŠŠ dataset æ”¾å…¥ DataLoader
data_iter = Data.DataLoader(
    dataset = dataset, # torch TensorDataset format
    batch_size = batch_size, # mini batch size
    shuffle = True, # æ˜¯å¦æ‰“ä¹±æ•°æ® (è®­ç»ƒé›†ä¸€èˆ¬éœ€è¦è¿›è¡Œæ‰“ä¹±)
    num_workers = 2, # å¤šçº¿ç¨‹æ¥è¯»æ•°æ®ï¼Œæ³¨æ„åœ¨Windowsä¸‹éœ€è¦è®¾ç½®ä¸º0
)


class LinearNet(nn.Module):
    def __init__(self, n_feature):
        super(LinearNet, self).__init__()
        self.linear = nn.Linear(n_feature, 1)

    # forward å®šä¹‰å‰å‘ä¼ æ’­
    def forward(self, x):
        y = self.linear(x)
        return y

net = LinearNet(num_inputs) # num_inputs: ç‰¹å¾æ•°
print(net)  # LinearNet( (linear): Linear(in_features=2, out_features=1, bias=True) )

# æƒé‡å’Œåå·®è¿›è¡Œåˆå§‹åŒ–
init.normal_(net[0].weight, mean=0, std=0.01)
init.constant_(net[0].bias, val=0)  #ä¹Ÿå¯ä»¥ç›´æ¥ä¿®æ”¹ bias çš„  data:net[0].bias.data.fill_(0)

# æŸå¤±å‡½æ•°
loss = nn.MSELoss()

# ä¼˜åŒ–å™¨
optimizer = optim.SGD(net.parameters(), lr=0.03)

epochs = 3
for i in range(1, epochs + 1):
    for X, y in data_iter:
        pred_y = net(X)
        l = loss(pred_y, y.view(-1, 1))
        optimizer.zero_grad()
        l.backward()
        optimizer.step()
    print('epoch %d,loss:%f' % (i, l.item()))